{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import SimpleRNN,LSTM, Dense, Input, BatchNormalization\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "data = open(\"../data/alice_wonderland.txt\",'r').read().lower()\n",
    "vocab = list(set(data))\n",
    "#len(vocab), len(data)\n",
    "data = \" \".join(data.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = { ch:i for i,ch in enumerate(vocab)}\n",
    "index_to_char = { i:ch for i,ch in enumerate(vocab)}\n",
    "\n",
    "#char_to_index, index_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_length = 40\n",
    "\n",
    "def change_data(data):\n",
    "    #Encode string to numeric values\n",
    "    encoded_data = [char_to_index[ch] for ch in data]\n",
    "    end_limit = len(encoded_data) - sentence_length\n",
    "    vocab_size = len(vocab)\n",
    "    sentences = [] \n",
    "    Y = []\n",
    "    for i in range(0,end_limit):\n",
    "        # generate sample\n",
    "        sentences.append(encoded_data[i:i+sentence_length]) \n",
    "        # generate output char\n",
    "        output = np.zeros((vocab_size,1))\n",
    "        output[encoded_data[i+sentence_length]] = True\n",
    "        Y.append(output)\n",
    "    # Now change sentences to one hot encoded data sequence\n",
    "    X = np.zeros((len(sentences),sentence_length,vocab_size))\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences[i])):\n",
    "            X[i][j][sentences[i][j]] = True\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = change_data(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(X) * 0.67)\n",
    "test_size = len(X) - train_size\n",
    "trainX, testX = X[0:train_size,:,:], X[train_size: ,:,:]\n",
    "trainY, testY = Y[0:train_size], Y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY = np.array(testY)\n",
    "testY = np.reshape(testY, (testY.shape[0],testY.shape[1]))\n",
    "trainY = np.array(trainY)\n",
    "trainY = np.reshape(trainY, (trainY.shape[0],trainY.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 40, 41)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 40, 41)            164       \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 40, 100)           14200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 40, 100)           400       \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 41)                4141      \n",
      "=================================================================\n",
      "Total params: 39,005\n",
      "Trainable params: 38,723\n",
      "Non-trainable params: 282\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_output_size = 100\n",
    "dropout_rate = 0\n",
    "\n",
    "# Input Layer\n",
    "ip = Input(shape=[sentence_length,len(vocab)])\n",
    "\n",
    "# LSTM Layer 1\n",
    "input_ = BatchNormalization(axis=-1)(ip)\n",
    "lstm_out = SimpleRNN(units=lstm_output_size, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)(input_)\n",
    "input_ = lstm_out\n",
    "\n",
    "# # LSTM Layer 2\n",
    "# input_ = BatchNormalization(axis=-1)(input_)\n",
    "# lstm_out = RNN(units=lstm_output_size, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)(input_)\n",
    "# input_ = lstm_out\n",
    "\n",
    "# # LSTM Layer 3\n",
    "# input_ = BatchNormalization(axis=-1)(input_)\n",
    "# lstm_out = LSTM(units=lstm_output_size, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate)(input_)\n",
    "# input_ = lstm_out\n",
    "\n",
    "# LSTM Layer 4\n",
    "input_ = BatchNormalization(axis=-1)(input_)\n",
    "lstm_out = SimpleRNN(units=lstm_output_size, return_sequences=False, dropout=dropout_rate, recurrent_dropout=dropout_rate)(input_)\n",
    "input_ = lstm_out\n",
    "\n",
    "# Output layer\n",
    "output = Dense(len(vocab), activation='softmax')(lstm_out)\n",
    "\n",
    "# Definingn Model\n",
    "model = Model(inputs=[ip],outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "21657/21657 [==============================] - 36s 2ms/step - loss: 2.4690 - acc: 0.3310\n",
      "Epoch 2/5\n",
      "21657/21657 [==============================] - 32s 1ms/step - loss: 1.9613 - acc: 0.4304\n",
      "Epoch 3/5\n",
      "21657/21657 [==============================] - 38s 2ms/step - loss: 1.8178 - acc: 0.4648\n",
      "Epoch 4/5\n",
      "21657/21657 [==============================] - 38s 2ms/step - loss: 1.7205 - acc: 0.4886\n",
      "Epoch 5/5\n",
      "21657/21657 [==============================] - 32s 1ms/step - loss: 1.6403 - acc: 0.5083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1d7f80860>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,trainY,epochs=5,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10667/10667 [==============================] - 8s 780us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8731717939976733, 0.4490484672493683]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the adventure of the three gables i don't\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_sentence = data[0:sentence_length+1] # Must be of size sentence_lenth + 1\n",
    "seed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the adventure of the three gables i don'tt  aonnee  thhee  wiitn  hheadr ywoarl ywoarl ywoarl ywoarl ywoarl ywoarl ywoarl ywoarl ywoarl ywoar\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_sentence = seed_sentence\n",
    "output = current_sentence\n",
    "for i in range(100):\n",
    "    currentX,_ = change_data(current_sentence)\n",
    "    currentY = model.predict(currentX)\n",
    "    predicted_char = index_to_char[np.argmax(currentY)]\n",
    "    current_sentence = current_sentence[1:] + predicted_char\n",
    "    output = output + predicted_char\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('test_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
