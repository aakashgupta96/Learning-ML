{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For random testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import sklearn.model_selection as cv\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from keras.models import Sequential, save_model, load_model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\", index_col=0)\n",
    "df = df.reset_index(drop=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_online = df[df[\"online_batch\"] == 1]\n",
    "df_offline = df[df[\"online_batch\"] == 0]\n",
    "#del df_online[\"online_batch\"],df_offline[\"online_batch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To take equal samples of both\n",
    "df_online_joining = df_online[(df_online[\"joining_result\"] == 1)]\n",
    "df_online_not_joining = df_online[(df_online[\"joining_result\"] == 0)].head(df_online_joining.shape[0])\n",
    "df_online = pd.concat([df_online_joining,df_online_not_joining])\n",
    "\n",
    "df_offline_joining = df_offline[(df_offline[\"joining_result\"] == 1)]\n",
    "df_offline_not_joining = df_offline[(df_offline[\"joining_result\"] == 0)].head(df_offline_joining.shape[0])\n",
    "df_offline = pd.concat([df_offline_joining,df_offline_not_joining])\n",
    "\n",
    "df = pd.concat([df_online,df_offline])\n",
    "df = shuffle(df)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df[\"joining_result\"] == 1).sum(), (df[\"joining_result\"] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1892, 13), (1892,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1].values\n",
    "Y = df.iloc[:,-1].values\n",
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(X[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1892, 26), (1892,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHotEncoder1= OneHotEncoder(n_values=[5,10],categorical_features = [2,X.shape[1]-1])\n",
    "X = oneHotEncoder1.fit_transform(X).toarray()\n",
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = [i for i in range(X.shape[1])]\n",
    "# cols.remove(0)\n",
    "# cols.remove(5)\n",
    "# X = X[:,cols]\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(X[:,X.shape[1]-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = cv.train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y_train.sum(), (Y_train == 0).sum(), Y_test.sum(), (Y_test == 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_101 (Dense)            (None, 20)                540       \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 30)                630       \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 40)                1240      \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 5,921\n",
      "Trainable params: 5,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1513 samples, validate on 379 samples\n",
      "Epoch 1/50\n",
      "1513/1513 [==============================] - 3s 2ms/step - loss: 0.3456 - acc: 0.5360 - val_loss: 0.6820 - val_acc: 0.6121\n",
      "Epoch 2/50\n",
      "1513/1513 [==============================] - 1s 461us/step - loss: 0.3282 - acc: 0.6325 - val_loss: 0.6435 - val_acc: 0.6069\n",
      "Epoch 3/50\n",
      "1513/1513 [==============================] - 1s 471us/step - loss: 0.3135 - acc: 0.6590 - val_loss: 0.6390 - val_acc: 0.6280\n",
      "Epoch 4/50\n",
      "1513/1513 [==============================] - 1s 533us/step - loss: 0.3017 - acc: 0.6794 - val_loss: 0.6308 - val_acc: 0.6438\n",
      "Epoch 5/50\n",
      "1513/1513 [==============================] - 1s 665us/step - loss: 0.3008 - acc: 0.6827 - val_loss: 0.6296 - val_acc: 0.6438\n",
      "Epoch 6/50\n",
      "1513/1513 [==============================] - 1s 555us/step - loss: 0.2936 - acc: 0.6973 - val_loss: 0.6428 - val_acc: 0.6438\n",
      "Epoch 7/50\n",
      "1513/1513 [==============================] - 1s 678us/step - loss: 0.2890 - acc: 0.7145 - val_loss: 0.6384 - val_acc: 0.6623\n",
      "Epoch 8/50\n",
      "1513/1513 [==============================] - 1s 522us/step - loss: 0.2866 - acc: 0.7019 - val_loss: 0.6363 - val_acc: 0.6649\n",
      "Epoch 9/50\n",
      "1513/1513 [==============================] - 1s 623us/step - loss: 0.2850 - acc: 0.7198 - val_loss: 0.6244 - val_acc: 0.6675\n",
      "Epoch 10/50\n",
      "1513/1513 [==============================] - 1s 792us/step - loss: 0.2866 - acc: 0.7151 - val_loss: 0.6248 - val_acc: 0.6807\n",
      "Epoch 11/50\n",
      "1513/1513 [==============================] - 1s 662us/step - loss: 0.2817 - acc: 0.7330 - val_loss: 0.6196 - val_acc: 0.6728\n",
      "Epoch 12/50\n",
      "1513/1513 [==============================] - 1s 542us/step - loss: 0.2811 - acc: 0.7317 - val_loss: 0.6176 - val_acc: 0.6649\n",
      "Epoch 13/50\n",
      "1513/1513 [==============================] - 1s 629us/step - loss: 0.2768 - acc: 0.7330 - val_loss: 0.6163 - val_acc: 0.6728\n",
      "Epoch 14/50\n",
      "1513/1513 [==============================] - 1s 552us/step - loss: 0.2779 - acc: 0.7350 - val_loss: 0.6123 - val_acc: 0.6781\n",
      "Epoch 15/50\n",
      "1513/1513 [==============================] - 1s 615us/step - loss: 0.2745 - acc: 0.7403 - val_loss: 0.6117 - val_acc: 0.6807\n",
      "Epoch 16/50\n",
      "1513/1513 [==============================] - 1s 785us/step - loss: 0.2752 - acc: 0.7350 - val_loss: 0.6081 - val_acc: 0.6834\n",
      "Epoch 17/50\n",
      "1513/1513 [==============================] - 1s 542us/step - loss: 0.2698 - acc: 0.7409 - val_loss: 0.6191 - val_acc: 0.6834\n",
      "Epoch 18/50\n",
      "1513/1513 [==============================] - 1s 625us/step - loss: 0.2709 - acc: 0.7363 - val_loss: 0.6081 - val_acc: 0.7018\n",
      "Epoch 19/50\n",
      "1513/1513 [==============================] - 1s 625us/step - loss: 0.2694 - acc: 0.7416 - val_loss: 0.6115 - val_acc: 0.6834\n",
      "Epoch 20/50\n",
      "1513/1513 [==============================] - 1s 573us/step - loss: 0.2700 - acc: 0.7422 - val_loss: 0.6090 - val_acc: 0.6939\n",
      "Epoch 21/50\n",
      "1513/1513 [==============================] - 1s 543us/step - loss: 0.2663 - acc: 0.7488 - val_loss: 0.5980 - val_acc: 0.6860\n",
      "Epoch 22/50\n",
      "1513/1513 [==============================] - 1s 626us/step - loss: 0.2666 - acc: 0.7475 - val_loss: 0.6031 - val_acc: 0.6887\n",
      "Epoch 23/50\n",
      "1513/1513 [==============================] - 1s 623us/step - loss: 0.2639 - acc: 0.7561 - val_loss: 0.5974 - val_acc: 0.6807\n",
      "Epoch 24/50\n",
      "1513/1513 [==============================] - 1s 505us/step - loss: 0.2621 - acc: 0.7475 - val_loss: 0.6008 - val_acc: 0.6860\n",
      "Epoch 25/50\n",
      "1513/1513 [==============================] - 1s 535us/step - loss: 0.2600 - acc: 0.7621 - val_loss: 0.6095 - val_acc: 0.6913\n",
      "Epoch 26/50\n",
      "1513/1513 [==============================] - 1s 670us/step - loss: 0.2585 - acc: 0.7548 - val_loss: 0.6035 - val_acc: 0.6834\n",
      "Epoch 27/50\n",
      "1513/1513 [==============================] - 1s 524us/step - loss: 0.2573 - acc: 0.7561 - val_loss: 0.6028 - val_acc: 0.6913\n",
      "Epoch 28/50\n",
      "1513/1513 [==============================] - 1s 625us/step - loss: 0.2567 - acc: 0.7488 - val_loss: 0.5954 - val_acc: 0.6781\n",
      "Epoch 29/50\n",
      "1513/1513 [==============================] - 1s 492us/step - loss: 0.2532 - acc: 0.7607 - val_loss: 0.5999 - val_acc: 0.6623\n",
      "Epoch 30/50\n",
      "1513/1513 [==============================] - 1s 730us/step - loss: 0.2533 - acc: 0.7621 - val_loss: 0.5929 - val_acc: 0.6860\n",
      "Epoch 31/50\n",
      "1513/1513 [==============================] - 1s 636us/step - loss: 0.2524 - acc: 0.7528 - val_loss: 0.6116 - val_acc: 0.6966\n",
      "Epoch 32/50\n",
      "1513/1513 [==============================] - 1s 623us/step - loss: 0.2510 - acc: 0.7594 - val_loss: 0.6099 - val_acc: 0.6675\n",
      "Epoch 33/50\n",
      "1513/1513 [==============================] - 1s 755us/step - loss: 0.2517 - acc: 0.7654 - val_loss: 0.6213 - val_acc: 0.6570\n",
      "Epoch 34/50\n",
      "1513/1513 [==============================] - 1s 526us/step - loss: 0.2531 - acc: 0.7508 - val_loss: 0.6073 - val_acc: 0.6755\n",
      "Epoch 35/50\n",
      "1513/1513 [==============================] - 1s 593us/step - loss: 0.2442 - acc: 0.7746 - val_loss: 0.6086 - val_acc: 0.6887\n",
      "Epoch 36/50\n",
      "1513/1513 [==============================] - 1s 662us/step - loss: 0.2473 - acc: 0.7588 - val_loss: 0.5927 - val_acc: 0.6966\n",
      "Epoch 37/50\n",
      "1513/1513 [==============================] - 1s 655us/step - loss: 0.2453 - acc: 0.7654 - val_loss: 0.6132 - val_acc: 0.6728\n",
      "Epoch 38/50\n",
      "1513/1513 [==============================] - 1s 642us/step - loss: 0.2467 - acc: 0.7588 - val_loss: 0.6124 - val_acc: 0.6755\n",
      "Epoch 39/50\n",
      "1513/1513 [==============================] - 1s 653us/step - loss: 0.2420 - acc: 0.7634 - val_loss: 0.6109 - val_acc: 0.6860\n",
      "Epoch 40/50\n",
      "1513/1513 [==============================] - 1s 613us/step - loss: 0.2431 - acc: 0.7667 - val_loss: 0.6176 - val_acc: 0.6755\n",
      "Epoch 41/50\n",
      "1513/1513 [==============================] - 1s 621us/step - loss: 0.2427 - acc: 0.7687 - val_loss: 0.6334 - val_acc: 0.6702\n",
      "Epoch 42/50\n",
      "1513/1513 [==============================] - 1s 644us/step - loss: 0.2429 - acc: 0.7673 - val_loss: 0.6379 - val_acc: 0.6570\n",
      "Epoch 43/50\n",
      "1513/1513 [==============================] - 1s 636us/step - loss: 0.2392 - acc: 0.7733 - val_loss: 0.6421 - val_acc: 0.6623\n",
      "Epoch 44/50\n",
      "1513/1513 [==============================] - 1s 612us/step - loss: 0.2391 - acc: 0.7693 - val_loss: 0.6102 - val_acc: 0.6755\n",
      "Epoch 45/50\n",
      "1513/1513 [==============================] - 1s 602us/step - loss: 0.2399 - acc: 0.7687 - val_loss: 0.6445 - val_acc: 0.6807\n",
      "Epoch 46/50\n",
      "1513/1513 [==============================] - 1s 594us/step - loss: 0.2373 - acc: 0.7726 - val_loss: 0.6163 - val_acc: 0.6544\n",
      "Epoch 47/50\n",
      "1513/1513 [==============================] - 1s 650us/step - loss: 0.2387 - acc: 0.7640 - val_loss: 0.6327 - val_acc: 0.6702\n",
      "Epoch 48/50\n",
      "1513/1513 [==============================] - 1s 621us/step - loss: 0.2362 - acc: 0.7680 - val_loss: 0.6350 - val_acc: 0.6464\n",
      "Epoch 49/50\n",
      "1513/1513 [==============================] - 1s 631us/step - loss: 0.2358 - acc: 0.7733 - val_loss: 0.6640 - val_acc: 0.6834\n",
      "Epoch 50/50\n",
      "1513/1513 [==============================] - 1s 782us/step - loss: 0.2361 - acc: 0.7826 - val_loss: 0.6460 - val_acc: 0.6464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f914c94e0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_shape=(X.shape[1],) ,activation='relu'))\n",
    "model.add(Dense(30, activation='sigmoid'))\n",
    "model.add(Dense(40, activation='sigmoid'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "class_weight = {0: 0.5, 1: 0.5}\n",
    "model.fit(X_scaled_train,Y_train,epochs=50,batch_size=10,class_weight=class_weight,validation_data=(X_scaled_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home/aakash/Drive/Dropbox/ML/Aakash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncoder1 = joblib.load(os.path.join(directory, 'oneHotEncoder.pkl'))\n",
    "scaler = joblib.load(os.path.join(directory, 'scaler.pkl'))\n",
    "model = load_model(os.path.join(directory, 'model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(20, input_dim=26))\n",
    "#     model.add(Dense(30, activation='sigmoid'))\n",
    "#     model.add(Dense(40, activation='sigmoid'))\n",
    "#     model.add(Dense(40, activation='relu'))\n",
    "#     model.add(Dense(30, activation='relu'))\n",
    "#     model.add(Dense(20, activation='sigmoid'))\n",
    "#     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# pipe = Pipeline([('oneHotEncoder', OneHotEncoder(n_values=[5,10],categorical_features = [2,12])),\n",
    "#                      ('scaler',StandardScaler(with_mean=False)), \n",
    "#                      ('nn', KerasClassifier(build_fn=model, epochs=40, batch_size=5))\n",
    "#                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = df.columns.tolist()\n",
    "# result = features.pop()\n",
    "# X = df[features]\n",
    "# Y = df[result]\n",
    "# X_train, X_test, Y_train, Y_test = cv.train_test_split(X.values,Y.values,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# directory = \"/home/aakash/Drive/Dropbox/ML/Aakash\"\n",
    "# model_step = pipe.steps.pop(-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(pipe, os.path.join(directory, 'pipeline.pkl'))\n",
    "# save_model(model_step.model, os.path.join(directory, 'model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.clear_session()\n",
    "# pipe = joblib.load(os.path.join(directory, 'pipeline.pkl'))\n",
    "# model = load_model(directory + '/model.h5')\n",
    "# pipe.steps.append(('nn', model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_scaled_test)\n",
    "y_pred_train = model.predict(X_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rounded = np.round(y_pred)\n",
    "y_pred_rounded_train = np.round(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.74      0.67       180\n",
      "          1       0.71      0.56      0.62       199\n",
      "\n",
      "avg / total       0.66      0.65      0.64       379\n",
      "\n",
      "[[134  46]\n",
      " [ 88 111]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.86      0.80       766\n",
      "          1       0.83      0.69      0.75       747\n",
      "\n",
      "avg / total       0.78      0.78      0.77      1513\n",
      "\n",
      "[[660 106]\n",
      " [232 515]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,y_pred_rounded))\n",
    "print(confusion_matrix(Y_test,y_pred_rounded))\n",
    "\n",
    "print(classification_report(Y_train,y_pred_rounded_train))\n",
    "print(confusion_matrix(Y_train,y_pred_rounded_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.71      0.66       180\n",
      "          1       0.70      0.61      0.65       199\n",
      "\n",
      "avg / total       0.66      0.66      0.66       379\n",
      "\n",
      "[[128  52]\n",
      " [ 78 121]]\n"
     ]
    }
   ],
   "source": [
    "#Trying to variate the threshold value\n",
    "threshold = 0.47\n",
    "rounded = np.zeros(y_pred.shape)\n",
    "for i in range(y_pred.shape[0]):\n",
    "    rounded[i][0] = (y_pred[i][0] >= threshold)\n",
    "print(classification_report(Y_test,rounded))\n",
    "print(confusion_matrix(Y_test,rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of samples lying in this range =  27.70448548812665\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "lower_limit = 0.3\n",
    "upper_limit = 0.7\n",
    "for i in range(y_pred.shape[0]):\n",
    "    if ((y_pred[i][0] >= lower_limit) & (y_pred[i][0] <= upper_limit)):\n",
    "        count += 1 \n",
    "print(\"Percentage of samples lying in this range = \", count*100/y_pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [round(0.1*i,1) for i in range(0,11)]\n",
    "joining_results = []\n",
    "not_joining_results = []\n",
    "for i in range(1,11):\n",
    "    lower_limit = ranges[i-1]\n",
    "    upper_limit = ranges[i]\n",
    "    joining = 0\n",
    "    not_joining = 0\n",
    "    for j in range(y_pred.shape[0]):\n",
    "        if((y_pred[j][0] >= lower_limit) & (y_pred[j][0] < upper_limit)):\n",
    "            if(Y_test[j] == 1):\n",
    "                joining += 1\n",
    "            else:\n",
    "                not_joining += 1\n",
    "    joining_results.append(joining)\n",
    "    not_joining_results.append(not_joining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 9, 31, 14, 22, 11, 13, 12, 12, 63]\n",
      "[36, 43, 31, 11, 13, 9, 12, 14, 3, 8]\n"
     ]
    }
   ],
   "source": [
    "print(joining_results)\n",
    "print(not_joining_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "joining_pos = [ i*10 + 2.5 for i in range(0,10)]\n",
    "not_joining_pos = [ i*10 + 7.5 for i in range(0,10)]\n",
    "plt.bar(joining_pos,joining_results,width=4, label=\"Joining Result\")\n",
    "plt.bar(not_joining_pos,not_joining_results,width=4, label=\"Not Joining Result\")\n",
    "plt.xticks([10*i for i in range(0,11)])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
