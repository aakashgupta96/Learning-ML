{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Backward Elimination with StartUps Profit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import model_selection as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(Y_true,Y_predicted):\n",
    "    nr = ((Y_true - Y_predicted)*(Y_true-Y_predicted)).sum()\n",
    "    dr = ((Y_true - Y_true.mean())*(Y_true-Y_true.mean())).sum()\n",
    "    result = 1 - (nr/dr)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Load the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/50_Startups.csv\")\n",
    "X = data.iloc[:,:-1].values\n",
    "Y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Label Encoding to change strings to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder_X = LabelEncoder()\n",
    "X[:,3] = labelEncoder_X.fit_transform(X[:,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One Hot Encoding to change categorical integers to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncoder = OneHotEncoder(categorical_features = [3])\n",
    "X = oneHotEncoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avoiding Dummy Variable Trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking one less dummy variable from each set of categorical dummy variables\n",
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Results without using Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93470684732824461"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = cv.train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,Y_train)\n",
    "Y_pred = regressor.predict(X_test)\n",
    "score(Y_test,Y_pred) #Score with all-in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using Backward Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1 (Selecting Significance Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding column of 1s for constant\n",
    "X = np.append(arr = np.ones((X.shape[0],1)).astype(int),values = X,axis=1)\n",
    "significance_level = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 (Include all features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_columns = [i for i in range(X.shape[-1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 and Step 4 (Fit Model with features available in included_columns and find p values for all untill all p values are less than significance level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished = False\n",
    "while not finished:\n",
    "    X_opt = X[:,included_columns]\n",
    "    regressor_OLS = sm.OLS(endog=Y,exog=X_opt).fit()\n",
    "    #print(regressor_OLS.summary())\n",
    "    table_data = regressor_OLS.summary().tables[1].data\n",
    "    p_values = [float(table_data[i][4]) for i in range(1,len(table_data))]\n",
    "    if(max(p_values) > 0.05): \n",
    "        column_to_remove = p_values.index(max(p_values))\n",
    "        #print(\"Removing column\",included_columns[column_to_remove])\n",
    "        del included_columns[column_to_remove]\n",
    "    else:\n",
    "        finished = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5 (Use available features to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94645876077872204"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modifying X according to results of backward elimination\n",
    "X = X[:,included_columns]\n",
    "X_train, X_test, Y_train, Y_test = cv.train_test_split(X,Y,test_size=0.2,random_state=0)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,Y_train)\n",
    "Y_pred = regressor.predict(X_test)\n",
    "score(Y_test,Y_pred) #Score with all-in model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
